---
title: "Process and merge data"
author: "Suparna Chaudhry and Andrew Heiss"
date: "Last run: `r format(Sys.time(), '%F')`"
output: 
  html_document:
    code_folding: show
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
knit_print.data.frame <- function(x, ...) {
  res <- paste(c('', '', kable_styling(kable(x, booktabs = TRUE))), collapse = '\n')
  asis_output(res)
}

registerS3method("knit_print", "data.frame", knit_print.data.frame)
registerS3method("knit_print", "grouped_df", knit_print.data.frame)

knitr::opts_chunk$set(fig.retina = 3,
                      tidy.opts = list(width.cutoff = 120),  # For code
                      options(width = 90),  # For output
                      fig.asp = 0.618, fig.width = 7, 
                      fig.align = "center", out.width = "85%")

options(dplyr.summarise.inform = FALSE,
        knitr.kable.NA = "")
```

# `targets` pipeline

Here's the general process for building and running this analysis. This is all done with [the magical **`targets`** package](https://docs.ropensci.org/targets/), which orchestrates all the dependencies automatically.

```{r show-targets-pipeline, echo=FALSE}
withr::with_dir(here::here(), {
  targets::tar_glimpse()
})
```


# Data cleaning

All the data processing is handled with dataset-specific functions that live in `R/funs_data-cleaning.R`, which **`targets`** then runs as needed. For the sake of transparency, here's that code:

```{r, code=xfun::read_utf8(here::here("R", "funs_data-cleaning.R")), eval=FALSE}
```
